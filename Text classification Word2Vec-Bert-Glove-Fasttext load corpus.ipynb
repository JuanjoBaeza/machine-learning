{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae44e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_name': 'Male terms and Female terms wrt Career and Family',\n",
       " 'result': 0.14108615275472403,\n",
       " 'weat': 0.14108615275472403,\n",
       " 'effect_size': 0.5770427540727928,\n",
       " 'p_value': nan}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://wefe.readthedocs.io/en/latest/loading_embeddings.html\n",
    "# https://crscardellino.ar/SBWCE/\n",
    "# https://github.com/dccuchile/spanish-word-embeddings#glove-embeddings-from-sbwc\n",
    "# https://github.com/LaurentVeyssier/Unsupervised-text-classification-with-BERT-embeddings/blob/main/unsupervised_text_classification_with_BERT.ipynb\n",
    "    \n",
    "from wefe.query import Query\n",
    "from wefe.word_embedding_model import WordEmbeddingModel\n",
    "from wefe.metrics.WEAT import WEAT\n",
    "from wefe.datasets.datasets import load_weat\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word_sets = load_weat()\n",
    "\n",
    "w2v_embeddings = KeyedVectors.load_word2vec_format(\"models/sbw_vectors.bin\", binary=True)\n",
    "word2vec = WordEmbeddingModel(w2v_embeddings, 'word2vec')\n",
    "\n",
    "query = Query([word_sets['male_terms'], word_sets['female_terms']],\n",
    "              [word_sets['career'], word_sets['family']],\n",
    "              ['Male terms', 'Female terms'],\n",
    "              ['Career', 'Family'])\n",
    "\n",
    "# instantiate the metric\n",
    "weat = WEAT()\n",
    "\n",
    "result = weat.run_query(query, word2vec)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1046298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('monarca', 0.8643362522125244), ('emperador', 0.8535380363464355), ('príncipe', 0.8354155421257019), ('soberano', 0.791935920715332), ('sultán', 0.7623835802078247), ('emir', 0.7423332929611206), ('faraón', 0.7316471338272095), ('califa', 0.7286533117294312), ('duque', 0.7255862951278687), ('regente', 0.7245674133300781)]\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/aitoralmeida/spanish_word2vec\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "model = Word2Vec.load(\"models/complete.model\")\n",
    "\n",
    "#vector = model.wv['rey']  # get numpy vector of a word\n",
    "sims = model.wv.most_similar('rey', topn=10)  # get other similar words\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4d8b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/63895772/understanding-get-sentence-vector-and-get-word-vector-for-fasttext\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from gensim.models.wrappers import FastText\n",
    "\n",
    "fasttext.util.download_model('es', if_exists='ignore')\n",
    "model = fasttext.load_model('cc.es.300.bin')\n",
    "\n",
    "#sentencia = model.get_sentence_vector('poder')\n",
    "#palabra   = model.get_word_vector('coche')\n",
    "#print(palabra)\n",
    "\n",
    "# get nearest neighbors for the interested words (100 neighbors)\n",
    "arancia_nn=model.get_nearest_neighbors('amor', k=2000)\n",
    "kiwi_nn=model.get_nearest_neighbors('castillo', k=2000)\n",
    "\n",
    "# get only words sets (discard the similarity cosine)\n",
    "arancia_nn_words=set([el[1] for el in arancia_nn])\n",
    "kiwi_nn_words=set([el[1] for el in kiwi_nn])\n",
    "\n",
    "# compute the intersection\n",
    "common_similar_words=arancia_nn_words.intersection(kiwi_nn_words)\n",
    "\n",
    "print(common_similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "207a8f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "True\n",
      "2.9.1\n",
      "Model: \"datasets/roberta-base/pytorch_model.bin\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " digits (InputLayer)         [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/PlanTL-GOB-ES/roberta-base-bne-sqac\n",
    "\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
    "from keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.is_built_with_cuda()) \n",
    "print(tf.__version__)\n",
    "\n",
    "def carga_modelo():\n",
    "\n",
    "    inputs  = keras.Input(shape=(784,), name='digits')\n",
    "    x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "    x = layers.Dense(64, activation='relu', name='dense_2')(x)\n",
    "    outputs = layers.Dense(10, activation='softmax', name='predictions')(x)\n",
    "    model   = keras.Model(inputs=inputs, outputs=outputs, name='datasets/roberta-base/pytorch_model.bin')\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "carga_modelo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e00357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    and  away   cow  diddle  dish   dog   hey  jumped  laughed  little  moon  \\\n",
      "0  0.00  0.00  0.00    0.89  0.00  0.00  0.45    0.00     0.00    0.00  0.00   \n",
      "1  0.00  0.00  0.42    0.00  0.00  0.00  0.00    0.42     0.00    0.00  0.42   \n",
      "2  0.00  0.00  0.00    0.00  0.00  0.37  0.00    0.00     0.37    0.37  0.00   \n",
      "3  0.36  0.36  0.00    0.00  0.36  0.00  0.00    0.00     0.00    0.00  0.00   \n",
      "\n",
      "   over   ran   see  spoon  sport  such   the    to  with  \n",
      "0  0.00  0.00  0.00   0.00   0.00  0.00  0.00  0.00  0.00  \n",
      "1  0.42  0.00  0.00   0.00   0.00  0.00  0.54  0.00  0.00  \n",
      "2  0.00  0.00  0.37   0.00   0.37  0.37  0.23  0.37  0.00  \n",
      "3  0.00  0.36  0.00   0.36   0.00  0.00  0.46  0.00  0.36  \n"
     ]
    }
   ],
   "source": [
    "# Libraries: TfidfVectorizer\n",
    "    \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'Hey diddle, diddle,',\n",
    "    'The cow jumped over the moon.',\n",
    "    'The little dog laughed to see such sport,',\n",
    "    'and the dish ran away with the spoon. '\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "df_tf_idf = pd.DataFrame(\n",
    "    data=X.todense().round(2),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "print(df_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2abb27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9944590330123901}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/vpkprasanna/usage-of-transformers-pipelines#Sentence_Classification\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "classifier(\"I don´t like a shit the film!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3363f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.963358998298645, 'start': 42, 'end': 50, 'answer': 'New-York'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_qa = pipeline('question-answering', model = 'distilbert-base-cased-distilled-squad')\n",
    "nlp_qa(context='Hugging Face is a French company based in New-York.', question='Where is based Hugging Face ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a30159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
