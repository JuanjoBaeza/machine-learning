{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "928c0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/ai-techsystems/spam-text-classification-on-cainvas-c0861db9393b\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "\n",
    "df = pd.read_csv('datasets/spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39563b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6      ham  Even my brother is not like to speak with me. ...\n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8     spam  WINNER!! As a valued network customer you have...\n",
       "9     spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c58a974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4516\n",
       "spam     641\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of score values\n",
    "df['Category'].value_counts()\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Distribution of score values\n",
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "799bd76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message\n",
       "0         0  Go until jurong point, crazy.. Available only ...\n",
       "1         0                      Ok lar... Joking wif u oni...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor... U c already then say...\n",
       "4         0  Nah I don't think he goes to usf, he lives aro...\n",
       "5         1  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6         0  Even my brother is not like to speak with me. ...\n",
       "7         0  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8         1  WINNER!! As a valued network customer you have...\n",
       "9         1  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels as 1 - spam or 0 - ham\n",
    "df['Category'] = df['Category'].apply(lambda x : 1 if x == 'spam' else 0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15f5f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove html tags\n",
    "def removeHTML(sentence):\n",
    "    regex = re.compile('<.*?>')\n",
    "    return re.sub(regex, ' ', sentence)\n",
    "\n",
    "# Remove URLs\n",
    "def removeURL(sentence):\n",
    "    regex = re.compile('http[s]?://\\S+')\n",
    "    return re.sub(regex, ' ', sentence)\n",
    "\n",
    "# remove numbers, punctuation and any special characters (keep only alphabets)\n",
    "def onlyAlphabets(sentence):\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    return re.sub(regex, ' ', sentence)\n",
    "\n",
    "def removeRecurring(sentence):\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1', sentence)\n",
    "\n",
    "# Defining stopwords\n",
    "stop = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6abb7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "sno = nltk.stem.SnowballStemmer('english')    # Initializing stemmer\n",
    "spam = []    # All words in positive reviews\n",
    "ham  = []    # All words in negative reviews\n",
    "all_sentences = []    # All cleaned sentences\n",
    "\n",
    "\n",
    "for x in range(len(df['Message'].values)):\n",
    "    review = df['Message'].values[x]\n",
    "    rating = df['Category'].values[x]\n",
    "\n",
    "    cleaned_sentence = []\n",
    "    sentence = removeURL(review) \n",
    "    sentence = removeHTML(sentence)\n",
    "    sentence = onlyAlphabets(sentence)\n",
    "    sentence = sentence.lower()   \n",
    "\n",
    "    sentence = removeRecurring(sentence)  \n",
    "\n",
    "    for word in sentence.split():\n",
    "        #if word not in stop:\n",
    "            stemmed = sno.stem(word)\n",
    "            cleaned_sentence.append(stemmed)\n",
    "            \n",
    "            if rating == 1 :\n",
    "                spam.append(stemmed)\n",
    "            else:\n",
    "                ham.append(stemmed)\n",
    "\n",
    "    all_sentences.append(' '.join(cleaned_sentence))\n",
    "\n",
    "# add as column in dataframe\n",
    "df['Cleaned'] = all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9095513f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazi avail onli in bugi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri in a wkli comp to win fa cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so earli hor u c alreadi then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i don t think he goe to usf he live around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>freemsg hey there darl it s been week s now an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>as per your request mell mell oru minnaminungi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>winner as a valu network custom you have been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>had your mobil month or more u r entitl to upd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message  \\\n",
       "0         0  Go until jurong point, crazy.. Available only ...   \n",
       "1         0                      Ok lar... Joking wif u oni...   \n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3         0  U dun say so early hor... U c already then say...   \n",
       "4         0  Nah I don't think he goes to usf, he lives aro...   \n",
       "5         1  FreeMsg Hey there darling it's been 3 week's n...   \n",
       "6         0  Even my brother is not like to speak with me. ...   \n",
       "7         0  As per your request 'Melle Melle (Oru Minnamin...   \n",
       "8         1  WINNER!! As a valued network customer you have...   \n",
       "9         1  Had your mobile 11 months or more? U R entitle...   \n",
       "\n",
       "                                             Cleaned  \n",
       "0  go until jurong point crazi avail onli in bugi...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri in a wkli comp to win fa cup final ...  \n",
       "3        u dun say so earli hor u c alreadi then say  \n",
       "4  nah i don t think he goe to usf he live around...  \n",
       "5  freemsg hey there darl it s been week s now an...  \n",
       "6  even my brother is not like to speak with me t...  \n",
       "7  as per your request mell mell oru minnaminungi...  \n",
       "8  winner as a valu network custom you have been ...  \n",
       "9  had your mobil month or more u r entitl to upd...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a3242ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Splitting into train, val and test set -- 80-10-10 split\n",
    "\n",
    "# First, an 80-20 split\n",
    "train_df, val_test_df = train_test_split(df, test_size = 0.2, random_state = 113)\n",
    "\n",
    "# Then split the 20% into half\n",
    "val_df, test_df = train_test_split(val_test_df, test_size = 0.5, random_state = 113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10836c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range = (1,1), max_features=20000)\n",
    "\n",
    "train_bow = cv.fit_transform(train_df['Cleaned'])\n",
    "val_bow = cv.transform(val_df['Cleaned'])\n",
    "test_bow = cv.transform(test_df['Cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b43d054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer().fit(train_bow)\n",
    "\n",
    "train_tf = tfidf.transform(train_bow)\n",
    "val_tf = tfidf.transform(val_bow)\n",
    "test_tf = tfidf.transform(test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3aa489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = train_tf.toarray()\n",
    "ytrain = train_df['Category']\n",
    "\n",
    "Xval = val_tf.toarray()\n",
    "yval = val_df['Category']\n",
    "\n",
    "ytest = test_df['Category']\n",
    "Xtest = test_tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3d5bcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.6710 - accuracy: 0.8759 - val_loss: 0.6455 - val_accuracy: 0.8566\n",
      "Epoch 2/64\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 0.6167 - accuracy: 0.8759 - val_loss: 0.5923 - val_accuracy: 0.8566\n",
      "Epoch 3/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.5625 - accuracy: 0.8759 - val_loss: 0.5411 - val_accuracy: 0.8566\n",
      "Epoch 4/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.5104 - accuracy: 0.8759 - val_loss: 0.4922 - val_accuracy: 0.8566\n",
      "Epoch 5/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.4605 - accuracy: 0.8759 - val_loss: 0.4451 - val_accuracy: 0.8566\n",
      "Epoch 6/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.4128 - accuracy: 0.8759 - val_loss: 0.4006 - val_accuracy: 0.8566\n",
      "Epoch 7/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.3685 - accuracy: 0.8759 - val_loss: 0.3606 - val_accuracy: 0.8566\n",
      "Epoch 8/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.3296 - accuracy: 0.8759 - val_loss: 0.3264 - val_accuracy: 0.8566\n",
      "Epoch 9/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.2962 - accuracy: 0.8759 - val_loss: 0.2979 - val_accuracy: 0.8566\n",
      "Epoch 10/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.2681 - accuracy: 0.8759 - val_loss: 0.2744 - val_accuracy: 0.8566\n",
      "Epoch 11/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.2445 - accuracy: 0.8759 - val_loss: 0.2549 - val_accuracy: 0.8566\n",
      "Epoch 12/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.2248 - accuracy: 0.8759 - val_loss: 0.2388 - val_accuracy: 0.8566\n",
      "Epoch 13/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.2085 - accuracy: 0.8759 - val_loss: 0.2257 - val_accuracy: 0.8566\n",
      "Epoch 14/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1947 - accuracy: 0.8759 - val_loss: 0.2146 - val_accuracy: 0.8566\n",
      "Epoch 15/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1831 - accuracy: 0.8759 - val_loss: 0.2054 - val_accuracy: 0.8566\n",
      "Epoch 16/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1732 - accuracy: 0.8759 - val_loss: 0.1979 - val_accuracy: 0.8566\n",
      "Epoch 17/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1648 - accuracy: 0.8759 - val_loss: 0.1914 - val_accuracy: 0.8566\n",
      "Epoch 18/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1575 - accuracy: 0.8759 - val_loss: 0.1859 - val_accuracy: 0.8566\n",
      "Epoch 19/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1511 - accuracy: 0.8759 - val_loss: 0.1812 - val_accuracy: 0.8566\n",
      "Epoch 20/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.1455 - accuracy: 0.8759 - val_loss: 0.1772 - val_accuracy: 0.8566\n",
      "Epoch 21/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1405 - accuracy: 0.8759 - val_loss: 0.1737 - val_accuracy: 0.8566\n",
      "Epoch 22/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1361 - accuracy: 0.8759 - val_loss: 0.1704 - val_accuracy: 0.8566\n",
      "Epoch 23/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1322 - accuracy: 0.8759 - val_loss: 0.1679 - val_accuracy: 0.8566\n",
      "Epoch 24/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1287 - accuracy: 0.8759 - val_loss: 0.1653 - val_accuracy: 0.8566\n",
      "Epoch 25/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1254 - accuracy: 0.8759 - val_loss: 0.1632 - val_accuracy: 0.8566\n",
      "Epoch 26/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1223 - accuracy: 0.8759 - val_loss: 0.1611 - val_accuracy: 0.8566\n",
      "Epoch 27/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.1195 - accuracy: 0.8759 - val_loss: 0.1590 - val_accuracy: 0.8566\n",
      "Epoch 28/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.1168 - accuracy: 0.8759 - val_loss: 0.1575 - val_accuracy: 0.8566\n",
      "Epoch 29/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.1144 - accuracy: 0.8759 - val_loss: 0.1559 - val_accuracy: 0.8566\n",
      "Epoch 30/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.1121 - accuracy: 0.8759 - val_loss: 0.1547 - val_accuracy: 0.8566\n",
      "Epoch 31/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.1099 - accuracy: 0.8759 - val_loss: 0.1540 - val_accuracy: 0.8566\n",
      "Epoch 32/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.1079 - accuracy: 0.9491 - val_loss: 0.1529 - val_accuracy: 0.9554\n",
      "Epoch 33/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.1060 - accuracy: 0.9838 - val_loss: 0.1522 - val_accuracy: 0.9554\n",
      "Epoch 34/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.1041 - accuracy: 0.9862 - val_loss: 0.1518 - val_accuracy: 0.9554\n",
      "Epoch 35/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.1024 - accuracy: 0.9884 - val_loss: 0.1512 - val_accuracy: 0.9612\n",
      "Epoch 36/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1008 - accuracy: 0.9905 - val_loss: 0.1505 - val_accuracy: 0.9593\n",
      "Epoch 37/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.0992 - accuracy: 0.9910 - val_loss: 0.1500 - val_accuracy: 0.9593\n",
      "Epoch 38/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.0977 - accuracy: 0.9920 - val_loss: 0.1500 - val_accuracy: 0.9593\n",
      "Epoch 39/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.0963 - accuracy: 0.9930 - val_loss: 0.1491 - val_accuracy: 0.9612\n",
      "Epoch 40/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.0949 - accuracy: 0.9942 - val_loss: 0.1494 - val_accuracy: 0.9593\n",
      "Epoch 41/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.0936 - accuracy: 0.9944 - val_loss: 0.1489 - val_accuracy: 0.9593\n",
      "Epoch 42/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.0923 - accuracy: 0.9952 - val_loss: 0.1487 - val_accuracy: 0.9593\n",
      "Epoch 43/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.0910 - accuracy: 0.9956 - val_loss: 0.1486 - val_accuracy: 0.9593\n",
      "Epoch 44/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.0899 - accuracy: 0.9956 - val_loss: 0.1484 - val_accuracy: 0.9593\n",
      "Epoch 45/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.0887 - accuracy: 0.9959 - val_loss: 0.1488 - val_accuracy: 0.9593\n",
      "Epoch 46/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.0876 - accuracy: 0.9959 - val_loss: 0.1486 - val_accuracy: 0.9574\n",
      "Epoch 47/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.0865 - accuracy: 0.9959 - val_loss: 0.1492 - val_accuracy: 0.9574\n",
      "Epoch 48/64\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.0854 - accuracy: 0.9959 - val_loss: 0.1484 - val_accuracy: 0.9574\n",
      "Epoch 49/64\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.0843 - accuracy: 0.9961 - val_loss: 0.1487 - val_accuracy: 0.9574\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(16, activation = 'relu', input_shape = Xtrain[0].shape),   \n",
    "    layers.Dense(4, activation = 'relu'),\n",
    "    layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "cb = [tf.keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True)]\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.0001), loss = tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, ytrain, validation_data = (Xval, yval), epochs = 64, callbacks = cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54a9d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12064392864704132, 0.9689922332763672]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(Xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11cf194c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Reverse is cheating. That is not mathematics.\n",
      "\n",
      "Cleaned sentence:  revers is cheat that is not mathemat\n",
      "\n",
      "True value:  0\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "Predicted value:  0 ( 0.011027836 --> 0 )\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(0, Xtest.shape[0] - 1)\n",
    "\n",
    "sentence = test_df['Message'].values[x]\n",
    "print(\"Sentence: \", sentence)\n",
    "\n",
    "cleaned_sentence = []\n",
    "sentence = removeURL(sentence) \n",
    "sentence = removeHTML(sentence)\n",
    "sentence = onlyAlphabets(sentence) \n",
    "sentence = sentence.lower() \n",
    "sentence = removeRecurring(sentence)\n",
    "\n",
    "for word in sentence.split():\n",
    "    #if word not in stop:\n",
    "        stemmed = sno.stem(word)\n",
    "        cleaned_sentence.append(stemmed)\n",
    "\n",
    "sentence = [' '.join(cleaned_sentence)]\n",
    "print(\"\\nCleaned sentence: \", sentence[0])\n",
    "\n",
    "sentence = cv.transform(sentence)\n",
    "sentence = tfidf.transform(sentence)\n",
    "\n",
    "print(\"\\nTrue value: \", test_df['Category'].values[x])\n",
    "\n",
    "pred = model.predict(sentence.toarray())[0][0]\n",
    "print(\"\\nPredicted value: \", int(pred>0.5), \"(\", pred, \"-->\", (pred>0.5).astype('int'), \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7da26f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/spam.model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf0c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
